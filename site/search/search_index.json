{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Finetune CLI","text":"<p>Finetune CLI is a powerful, modular, and interactive command-line tool for fine-tuning Large Language Models (LLMs).</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Unified Workflow: A guided 12-step wizard for end-to-end fine-tuning.</li> <li>Multiple Techniques: Support for LoRA, QLoRA, and Prompt Tuning.</li> <li>Benchmarking: Built-in evaluation with ROUGE and other metrics.</li> <li>Model Support: Works with any HuggingFace Causal LM (GPT-2, Llama 2, Mistral, etc.).</li> <li>Memory Efficient: Run 7B+ models on consumer hardware with 4-bit quantization.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Install the package:</p> <pre><code>pip install .\n</code></pre> <p>Run the interactive wizard:</p> <pre><code>finetune-cli finetune run\n</code></pre> <p>Check out the Quick Start guide to begin!</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#021-2025-11-26","title":"[0.2.1] - 2025-11-26","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>ImportError Fix: Fixed <code>ImportError: cannot import name 'app'</code> by moving app definition to <code>finetunecli/__init__.py</code>.</li> <li>Command Not Found: Fixed <code>finetune-cli</code> command not found issue by reinstalling package with correct entry points.</li> <li>Benchmark AttributeError: Fixed <code>AttributeError: 'str' object has no attribute 'get'</code> in benchmarking by implementing proper dataset sampling for HuggingFace Datasets.</li> <li>QLoRA Target Modules: Fixed <code>ValueError</code> in QLoRA training by implementing auto-detection of target modules for different model architectures (GPT-2, Llama, etc.).</li> </ul>"},{"location":"changelog/#improved","title":"Improved","text":"<ul> <li>Learning Rate Input: Updated CLI to accept scientific notation (e.g., <code>2e-4</code>) for learning rate input.</li> <li>Test Organization: Organized test scripts into <code>tests/</code> directory with proper structure.</li> </ul>"},{"location":"changelog/#020-2025-11-26","title":"[0.2.0] - 2025-11-26","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Unified Interactive CLI: New <code>finetune run</code> command with 12-step wizard.</li> <li>QLoRA Support: 4-bit quantization for memory-efficient training.</li> <li>Prompt Tuning Support: Parameter-efficient soft prompt training.</li> <li>Hierarchical Menus: Organized technique selection.</li> <li>Documentation: Comprehensive guides and API docs.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Refactored core logic into modular <code>finetunecli</code> package.</li> <li>Updated <code>requirements.txt</code> with <code>bitsandbytes</code>.</li> </ul>"},{"location":"changelog/#010-initial-release","title":"[0.1.0] - Initial Release","text":"<ul> <li>Basic LoRA fine-tuning.</li> <li>ROUGE benchmarking.</li> <li>Simple CLI interface.</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for considering contributing to the LLM Fine-Tuning CLI Tool!</p>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":""},{"location":"contributing/#reporting-bugs","title":"Reporting Bugs","text":"<ol> <li>Check if the bug has already been reported</li> <li>Open a new issue with:</li> <li>Clear title and description</li> <li>Steps to reproduce</li> <li>Expected vs actual behavior</li> <li>System information</li> </ol>"},{"location":"contributing/#suggesting-features","title":"Suggesting Features","text":"<ol> <li>Open an issue with tag <code>enhancement</code></li> <li>Describe the feature and use case</li> <li>Provide examples if possible</li> </ol>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li> <li>Commit your changes (<code>git commit -m 'Add amazing feature'</code>)</li> <li>Push to branch (<code>git push origin feature/amazing-feature</code>)</li> <li>Open a Pull Request</li> </ol>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<pre><code>git clone https://github.com/Abdur-azure/finetune_cli.git\ncd finetune_cli\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -r requirements.txt\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8</li> <li>Add docstrings to functions</li> <li>Include type hints</li> <li>Write unit tests for new features</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"api/functions/","title":"Utility Functions","text":""},{"location":"api/functions/#finetunecliutilsdataset_loader","title":"<code>finetunecli.utils.dataset_loader</code>","text":""},{"location":"api/functions/#load_json_datasetpath-str","title":"<code>load_json_dataset(path: str)</code>","text":"<p>Loads a JSON dataset from a local file. *   Returns: <code>datasets.Dataset</code> object.</p>"},{"location":"api/functions/#finetuneclibenchmarkingrouge_metric","title":"<code>finetunecli.benchmarking.rouge_metric</code>","text":""},{"location":"api/functions/#rougemetriccomputepredictions-references","title":"<code>RougeMetric.compute(predictions, references)</code>","text":"<p>Computes ROUGE-1, ROUGE-2, and ROUGE-L scores.</p>"},{"location":"api/functions/#finetunecliquantizationqloraqlora_utils","title":"<code>finetunecli.quantization.qlora.qlora_utils</code>","text":""},{"location":"api/functions/#estimate_memory_savingsbase_bits-quant_bits-lora_r-model_params","title":"<code>estimate_memory_savings(base_bits, quant_bits, lora_r, model_params)</code>","text":"<p>Estimates VRAM savings for QLoRA vs full fine-tuning.</p>"},{"location":"api/llm-finetuner/","title":"LLMFineTuner Class","text":"<p>The core class orchestrating the fine-tuning process.</p>"},{"location":"api/llm-finetuner/#finetuneclitrainingtrainerllmfinetuner","title":"<code>finetunecli.training.trainer.LLMFineTuner</code>","text":""},{"location":"api/llm-finetuner/#__init__self-model_name-str-dataset_path-str-output_dir-str","title":"<code>__init__(self, model_name: str, dataset_path: str, output_dir: str)</code>","text":"<p>Initialize the fine-tuner.</p> <ul> <li><code>model_name</code>: HuggingFace model ID or local path.</li> <li><code>dataset_path</code>: Path to training data.</li> <li><code>output_dir</code>: Directory to save results.</li> </ul>"},{"location":"api/llm-finetuner/#load_modelself","title":"<code>load_model(self)</code>","text":"<p>Loads the base model and tokenizer. Handles device mapping (CPU/GPU).</p>"},{"location":"api/llm-finetuner/#prepare_datasetself","title":"<code>prepare_dataset(self)</code>","text":"<p>Loads and processes the dataset. *   Tokenizes input text. *   Handles padding and truncation.</p>"},{"location":"api/llm-finetuner/#setup_loraself-r8-alpha32-dropout01","title":"<code>setup_lora(self, r=8, alpha=32, dropout=0.1)</code>","text":"<p>Configures the model for LoRA fine-tuning using <code>peft</code>.</p>"},{"location":"api/llm-finetuner/#trainself-epochs3-batch_size4-lr2e-4","title":"<code>train(self, epochs=3, batch_size=4, lr=2e-4)</code>","text":"<p>Executes the training loop. *   Uses <code>transformers.Trainer</code>. *   Saves checkpoints.</p>"},{"location":"api/llm-finetuner/#benchmarkself-metricrouge","title":"<code>benchmark(self, metric=\"rouge\")</code>","text":"<p>Evaluates the model using the specified metric.</p>"},{"location":"examples/advanced/","title":"Advanced Examples","text":""},{"location":"examples/advanced/#qlora-on-llama-2-7b","title":"QLoRA on Llama-2-7b","text":"<p>Goal: Fine-tune a 7B parameter model on a consumer GPU (e.g., RTX 3060).</p> <p>Prerequisites: *   <code>bitsandbytes</code> installed *   HuggingFace token for Llama-2 access</p> <p>Settings: *   Model: <code>meta-llama/Llama-2-7b-hf</code> *   Technique: <code>QLoRA</code> *   Bits: <code>4</code> *   Quant Type: <code>nf4</code> *   Rank: <code>64</code> (Higher rank possible due to memory savings)</p>"},{"location":"examples/advanced/#prompt-tuning-for-multi-tasking","title":"Prompt Tuning for Multi-Tasking","text":"<p>Goal: Use one frozen model for multiple tasks.</p> <p>Task 1: Summarization *   Init Text: \"Summarize the following article:\" *   Virtual Tokens: <code>20</code> *   Output Dir: <code>./prompts/summarization</code></p> <p>Task 2: Translation *   Init Text: \"Translate to Spanish:\" *   Virtual Tokens: <code>20</code> *   Output Dir: <code>./prompts/translation</code></p> <p>Inference: Load the base model once, then swap the prompt adapter based on the user's request.</p>"},{"location":"examples/basic/","title":"Basic Examples","text":""},{"location":"examples/basic/#fine-tuning-gpt-2-for-sentiment-analysis","title":"Fine-tuning GPT-2 for Sentiment Analysis","text":"<p>Goal: Teach GPT-2 to classify text as Positive or Negative.</p> <p>Dataset (<code>sentiment.json</code>): <pre><code>[\n  {\"input\": \"I love this movie!\", \"output\": \"Positive\"},\n  {\"input\": \"This is terrible.\", \"output\": \"Negative\"}\n]\n</code></pre></p> <p>Command: <pre><code>finetune-cli finetune run\n</code></pre></p> <p>Settings: *   Model: <code>gpt2</code> *   Technique: <code>LoRA</code> *   Rank: <code>8</code> *   Epochs: <code>3</code></p>"},{"location":"examples/basic/#fine-tuning-opt-125m-for-chat","title":"Fine-tuning OPT-125m for Chat","text":"<p>Goal: Create a simple chatbot.</p> <p>Dataset (<code>chat.json</code>): <pre><code>[\n  {\"input\": \"User: Hello\\nAssistant:\", \"output\": \"Hi there! How can I help?\"},\n  {\"input\": \"User: What is AI?\\nAssistant:\", \"output\": \"AI stands for Artificial Intelligence.\"}\n]\n</code></pre></p> <p>Settings: *   Model: <code>facebook/opt-125m</code> *   Technique: <code>LoRA</code> *   Rank: <code>16</code></p>"},{"location":"examples/use-cases/","title":"Use Cases","text":"<p>Choosing the right technique for your needs.</p>"},{"location":"examples/use-cases/#when-to-use-lora","title":"When to use LoRA?","text":"<ul> <li>Scenario: You have a decent GPU (16GB+) and want a balance of speed and quality.</li> <li>Pros: Standard, well-supported, fast training.</li> <li>Cons: Higher memory usage than QLoRA.</li> </ul>"},{"location":"examples/use-cases/#when-to-use-qlora","title":"When to use QLoRA?","text":"<ul> <li>Scenario: You have limited VRAM (e.g., 8GB-12GB) but want to fine-tune large models (7B+).</li> <li>Pros: Massive memory savings (up to 60%), allows training 7B models on consumer cards.</li> <li>Cons: Slightly slower training due to quantization overhead.</li> </ul>"},{"location":"examples/use-cases/#when-to-use-prompt-tuning","title":"When to use Prompt Tuning?","text":"<ul> <li>Scenario: You need to serve many different tasks from one model, or storage is a major concern.</li> <li>Pros: Tiny artifacts (KB), base model stays frozen, easy to switch tasks.</li> <li>Cons: May not reach the same peak performance as LoRA for complex tasks.</li> </ul>"},{"location":"getting-started/first-finetune/","title":"Your First Fine-tune","text":"<p>This guide walks you through fine-tuning GPT-2 on a custom dataset using LoRA.</p>"},{"location":"getting-started/first-finetune/#prerequisites","title":"Prerequisites","text":"<ul> <li>Finetune CLI installed (<code>pip install .</code>)</li> <li>A dataset file (e.g., <code>data.json</code>)</li> </ul>"},{"location":"getting-started/first-finetune/#step-1-prepare-data","title":"Step 1: Prepare Data","text":"<p>Create a file named <code>data.json</code> with your training examples:</p> <pre><code>[\n  {\n    \"input\": \"Translate to French: Hello, how are you?\",\n    \"output\": \"Bonjour, comment allez-vous?\"\n  },\n  {\n    \"input\": \"Translate to French: The weather is nice.\",\n    \"output\": \"Il fait beau.\"\n  }\n]\n</code></pre>"},{"location":"getting-started/first-finetune/#step-2-run-the-cli","title":"Step 2: Run the CLI","text":"<p>Start the interactive session:</p> <pre><code>finetune-cli finetune run\n</code></pre>"},{"location":"getting-started/first-finetune/#step-3-follow-the-wizard","title":"Step 3: Follow the Wizard","text":"<ol> <li>Model: Enter <code>gpt2</code>.</li> <li>Dataset: Enter <code>./data.json</code>.</li> <li>Technique: Select <code>1</code> (Quantization) -&gt; <code>1</code> (LoRA).</li> <li>Benchmark: Select <code>1</code> (ROUGE).</li> <li>Output: Press Enter to use default.</li> <li>Base Benchmark: The CLI will evaluate the base GPT-2 model.</li> <li>Parameters:<ul> <li>Rank \u00ae: <code>8</code></li> <li>Alpha: <code>32</code></li> <li>Dropout: <code>0.1</code></li> <li>Epochs: <code>3</code></li> </ul> </li> <li>Training: Watch the progress bar as the model trains.</li> <li>Evaluation: See how much the model improved!</li> </ol>"},{"location":"getting-started/first-finetune/#step-4-use-your-model","title":"Step 4: Use Your Model","text":"<p>Your fine-tuned model is saved in the output directory. You can load it using <code>peft</code>:</p> <pre><code>from peft import PeftModel\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nbase_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\nmodel = PeftModel.from_pretrained(base_model, \"./finetuned_lora\")\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n\ninputs = tokenizer(\"Translate to French: Good morning\", return_tensors=\"pt\")\noutputs = model.generate(**inputs, max_new_tokens=20)\nprint(tokenizer.decode(outputs[0]))\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will help you set up the LLM Fine-Tuning CLI Tool on your system.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing, ensure you have:</p> <ul> <li>Python 3.8 or higher</li> <li>pip (Python package manager)</li> <li>(Optional) CUDA-capable GPU for faster training</li> </ul>"},{"location":"getting-started/installation/#installation-steps","title":"Installation Steps","text":""},{"location":"getting-started/installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/Abdur-azure/finetune_cli.git\ncd finetune_cli\n</code></pre>"},{"location":"getting-started/installation/#2-create-virtual-environment-recommended","title":"2. Create Virtual Environment (Recommended)","text":"Linux/macOSWindows <pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre> <pre><code>python -m venv venv\nvenv\\Scripts\\activate\n</code></pre>"},{"location":"getting-started/installation/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code>pip install --upgrade pip\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#4-verify-installation","title":"4. Verify Installation","text":"<pre><code>python finetune_cli.py --help\n</code></pre>"},{"location":"getting-started/installation/#gpu-setup-optional","title":"GPU Setup (Optional)","text":"<p>For CUDA support:</p> <pre><code># Check CUDA version\nnvidia-smi\n\n# Install PyTorch with CUDA support\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":"<p>Common Issues</p> <p>Issue: <code>ModuleNotFoundError</code></p> <p>Solution: Ensure all dependencies are installed: <pre><code>pip install -r requirements.txt\n</code></pre></p> <p>GPU Not Detected</p> <p>The tool will automatically fall back to CPU if no GPU is detected. To force GPU usage: <pre><code>export CUDA_VISIBLE_DEVICES=0\n</code></pre></p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide</li> <li>Your First Fine-tune</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get up and running with Finetune CLI in minutes.</p>"},{"location":"getting-started/quickstart/#interactive-mode","title":"Interactive Mode","text":"<p>The easiest way to use Finetune CLI is through the interactive wizard:</p> <pre><code>finetune-cli finetune run\n</code></pre> <p>This command launches a 12-step interactive workflow that guides you through:</p> <ol> <li>Model Selection: Choose any HuggingFace model or local path.</li> <li>Dataset Selection: Use local JSON files or HuggingFace datasets.</li> <li>Technique Selection: Choose from LoRA, QLoRA, or Prompt Tuning.</li> <li>Benchmarking: Select metrics like ROUGE to evaluate performance.</li> <li>Training: Configure parameters and start fine-tuning.</li> <li>Evaluation: Compare base vs. fine-tuned model performance.</li> <li>Saving &amp; Uploading: Save your model and optionally upload to HuggingFace.</li> </ol>"},{"location":"getting-started/quickstart/#command-line-arguments","title":"Command Line Arguments","text":"<p>For automation or advanced usage, you can pass arguments directly to the specific subcommands (legacy mode):</p> <pre><code># Train with LoRA\nfinetune-cli train start --model gpt2 --data ./data/train.json --out ./output\n\n# Benchmark a model\nfinetune-cli benchmark rouge --model ./output --data ./data/test.json\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Follow the First Fine-tune guide for a detailed tutorial.</li> <li>Check out the User Guide for in-depth documentation.</li> </ul>"},{"location":"troubleshooting/common-issues/","title":"Common Issues","text":""},{"location":"troubleshooting/common-issues/#cuda-out-of-memory-oom","title":"CUDA Out of Memory (OOM)","text":"<p>Symptoms: Training crashes with <code>RuntimeError: CUDA out of memory</code>.</p> <p>Solutions: 1.  Reduce Batch Size: Try <code>batch_size=1</code> or <code>2</code>. 2.  Use Gradient Accumulation: Simulate larger batches. 3.  Switch to QLoRA: Use 4-bit quantization. 4.  Reduce Context Length: If your data is very long, truncate it.</p>"},{"location":"troubleshooting/common-issues/#bitsandbytes-not-found","title":"bitsandbytes Not Found","text":"<p>Symptoms: <code>ImportError: No module named 'bitsandbytes'</code> when using QLoRA.</p> <p>Solutions: 1.  Install it: <code>pip install bitsandbytes</code>. 2.  Windows: You may need a specific version or build for Windows. Check the <code>bitsandbytes-windows</code> package if the official one fails.</p>"},{"location":"troubleshooting/common-issues/#dataset-errors","title":"Dataset Errors","text":"<p>Symptoms: <code>KeyError: 'input'</code></p> <p>Solutions: Ensure your JSON file has the correct structure. It must be a list of objects, each having <code>input</code> and <code>output</code> keys.</p>"},{"location":"troubleshooting/common-issues/#importerror-cannot-import-name-app","title":"ImportError: cannot import name 'app'","text":"<p>Symptoms: <code>ImportError: cannot import name 'app' from 'finetunecli'</code> when running <code>finetune-cli</code>.</p> <p>Solutions: 1. Reinstall the package: <code>pip install -e .</code> 2. Ensure you're in the virtual environment if using one. 3. Check that <code>finetunecli/__init__.py</code> contains the <code>app</code> definition.</p>"},{"location":"troubleshooting/common-issues/#command-not-found-finetune-cli","title":"Command Not Found: finetune-cli","text":"<p>Symptoms: <code>finetune-cli: command not found</code> or similar error.</p> <p>Solutions: 1. Activate Virtual Environment: If using a virtual environment, activate it first:    - Windows: <code>.\\venv\\Scripts\\activate</code>    - Linux/Mac: <code>source venv/bin/activate</code> 2. Run Directly: Use the full path: <code>.\\venv\\Scripts\\finetune-cli</code> (Windows) or <code>./venv/bin/finetune-cli</code> (Linux/Mac). 3. Use Python Module: Run as a module: <code>python -m finetunecli</code> 4. Reinstall Package: <code>pip install -e .</code> to ensure entry points are registered.</p>"},{"location":"troubleshooting/common-issues/#qlora-target-modules-error","title":"QLoRA Target Modules Error","text":"<p>Symptoms: <code>ValueError: Target modules {'q_proj', 'k_proj', 'v_proj', 'o_proj'} not found in the base model</code>.</p> <p>Solutions: This has been fixed in v0.2.1. The system now auto-detects the correct target modules for your model architecture. Update to the latest version.</p>"},{"location":"troubleshooting/common-issues/#benchmark-attributeerror","title":"Benchmark AttributeError","text":"<p>Symptoms: <code>AttributeError: 'str' object has no attribute 'get'</code> during benchmarking.</p> <p>Solutions: This has been fixed in v0.2.1. The issue was with dataset sampling. Update to the latest version.</p>"},{"location":"troubleshooting/faq/","title":"Frequently Asked Questions","text":""},{"location":"troubleshooting/faq/#can-i-fine-tune-on-cpu","title":"Can I fine-tune on CPU?","text":"<p>Technically yes, but it will be extremely slow. A GPU is highly recommended.</p>"},{"location":"troubleshooting/faq/#how-long-does-training-take","title":"How long does training take?","text":"<p>It depends on the model size, dataset size, and hardware. *   GPT-2 on 100 examples: ~2 minutes. *   Llama-2-7b on 1000 examples: ~1-2 hours on a decent GPU.</p>"},{"location":"troubleshooting/faq/#can-i-use-my-own-base-model","title":"Can I use my own base model?","text":"<p>Yes, as long as it's compatible with <code>transformers.AutoModelForCausalLM</code>.</p>"},{"location":"troubleshooting/faq/#where-are-the-models-saved","title":"Where are the models saved?","text":"<p>By default, in a folder named <code>finetuned_&lt;technique&gt;</code> (e.g., <code>finetuned_lora</code>) in your current directory, or whatever path you specified.</p>"},{"location":"user-guide/benchmarking/","title":"Benchmarking","text":"<p>Evaluating your model is crucial to measure improvement.</p>"},{"location":"user-guide/benchmarking/#rouge","title":"ROUGE","text":"<p>Recall-Oriented Understudy for Gisting Evaluation</p> <ul> <li>ROUGE-1: Overlap of unigrams (single words).</li> <li>ROUGE-2: Overlap of bigrams (two-word sequences).</li> <li>ROUGE-L: Longest Common Subsequence.</li> </ul> <p>ROUGE is excellent for summarization and translation tasks where there is a reference \"gold standard\" output.</p>"},{"location":"user-guide/benchmarking/#other-metrics-coming-soon","title":"Other Metrics (Coming Soon)","text":"<ul> <li>BLEU: Standard for machine translation.</li> <li>BERTScore: Semantic similarity using BERT embeddings.</li> <li>Perplexity: Measure of how well the model predicts the sample text.</li> </ul>"},{"location":"user-guide/benchmarking/#the-comparison-step","title":"The Comparison Step","text":"<p>The CLI automatically runs the selected benchmark on: 1.  The Base Model (before training). 2.  The Fine-tuned Model (after training).</p> <p>It then displays a side-by-side comparison table showing the percentage improvement.</p>"},{"location":"user-guide/dataset-loading/","title":"Dataset Loading","text":"<p>Finetune CLI supports flexible dataset loading options.</p>"},{"location":"user-guide/dataset-loading/#local-json-files","title":"Local JSON Files","text":"<p>The simplest format is a JSON list of objects with <code>input</code> and <code>output</code> keys:</p> <pre><code>[\n  {\n    \"input\": \"User prompt here\",\n    \"output\": \"Desired model response\"\n  },\n  ...\n]\n</code></pre>"},{"location":"user-guide/dataset-loading/#huggingface-datasets","title":"HuggingFace Datasets","text":"<p>You can load datasets directly from the HuggingFace Hub (implementation pending in unified CLI, currently falls back to local/sample).</p>"},{"location":"user-guide/dataset-loading/#data-processing","title":"Data Processing","text":"<p>The CLI automatically handles: *   Tokenization *   Padding/Truncation (max length 512) *   Batching</p> <p>Ensure your data is clean and representative of the task you want the model to perform.</p>"},{"location":"user-guide/huggingface-upload/","title":"HuggingFace Upload","text":"<p>Share your fine-tuned models with the community.</p>"},{"location":"user-guide/huggingface-upload/#prerequisites","title":"Prerequisites","text":"<ol> <li>HuggingFace Account: Create one at huggingface.co.</li> <li>Access Token: Get a Write token from Settings &gt; Tokens.</li> </ol>"},{"location":"user-guide/huggingface-upload/#the-upload-process","title":"The Upload Process","text":"<p>At the end of the interactive workflow, the CLI asks:</p> <pre><code>\ud83e\udd17 Upload model to HuggingFace Hub? [y/N]:\n</code></pre> <p>If you select <code>y</code>:</p> <ol> <li>Repository Name: Enter <code>username/repo-name</code>.</li> <li>Token: Paste your Write token (input will be hidden).</li> <li>Privacy: Choose public or private repository.</li> </ol> <p>The CLI will: 1.  Login to HuggingFace. 2.  Create the repository if it doesn't exist. 3.  Upload all model artifacts (adapters, tokenizer configs). 4.  Provide a direct link to your model.</p>"},{"location":"user-guide/huggingface-upload/#using-uploaded-models","title":"Using Uploaded Models","text":"<p>Users can load your model directly:</p> <pre><code>from peft import PeftModel\nmodel = PeftModel.from_pretrained(base_model, \"username/repo-name\")\n</code></pre>"},{"location":"user-guide/lora-configuration/","title":"LoRA &amp; QLoRA Configuration","text":"<p>Understanding the hyperparameters is key to successful fine-tuning.</p>"},{"location":"user-guide/lora-configuration/#lora-parameters","title":"LoRA Parameters","text":"<ul> <li>Rank \u00ae: The dimension of the low-rank matrices.<ul> <li>Typical values: 8, 16, 32, 64.</li> <li>Effect: Higher rank = more trainable parameters = potentially better performance but higher memory usage.</li> </ul> </li> <li>Alpha: Scaling factor for LoRA weights.<ul> <li>Rule of thumb: Set alpha to 2x the rank (e.g., if r=16, alpha=32).</li> </ul> </li> <li>Dropout: Probability of dropping out neurons during training.<ul> <li>Typical values: 0.05 - 0.1.</li> <li>Effect: Prevents overfitting.</li> </ul> </li> </ul>"},{"location":"user-guide/lora-configuration/#qlora-specifics","title":"QLoRA Specifics","text":"<p>QLoRA adds quantization parameters:</p> <ul> <li>Bits: 4 or 8.<ul> <li>Recommendation: 4-bit for maximum memory savings.</li> </ul> </li> <li>Quant Type: <code>nf4</code> (Normal Float 4) or <code>fp4</code>.<ul> <li>Recommendation: <code>nf4</code> is information-theoretically optimal for normal distributions.</li> </ul> </li> <li>Double Quant: Quantize the quantization constants.<ul> <li>Recommendation: Enable for extra memory savings.</li> </ul> </li> </ul>"},{"location":"user-guide/lora-configuration/#prompt-tuning-parameters","title":"Prompt Tuning Parameters","text":"<ul> <li>Virtual Tokens: Number of soft prompt tokens prepended to input.<ul> <li>Typical values: 8 - 100.</li> </ul> </li> <li>Initialization:<ul> <li><code>TEXT</code>: Initialize from a natural language description (Recommended).</li> <li><code>RANDOM</code>: Random initialization (Harder to train).</li> </ul> </li> </ul>"},{"location":"user-guide/model-selection/","title":"Model Selection","text":"<p>Finetune CLI supports a wide range of Large Language Models.</p>"},{"location":"user-guide/model-selection/#huggingface-models","title":"HuggingFace Models","text":"<p>You can use any Causal LM available on the HuggingFace Hub. Simply provide the repository ID:</p> <ul> <li><code>gpt2</code></li> <li><code>facebook/opt-125m</code></li> <li><code>meta-llama/Llama-2-7b-hf</code></li> <li><code>mistralai/Mistral-7B-v0.1</code></li> </ul>"},{"location":"user-guide/model-selection/#local-models","title":"Local Models","text":"<p>You can also provide an absolute path to a local directory containing a HuggingFace-compatible model:</p> <ul> <li><code>/path/to/my/local/model</code></li> </ul>"},{"location":"user-guide/model-selection/#considerations","title":"Considerations","text":"<ul> <li>Memory: Ensure your GPU has enough VRAM for the selected model. Use QLoRA for larger models on consumer hardware.</li> <li>Access: Some models (like Llama 2) require accepting license terms on HuggingFace and logging in with a token.</li> </ul>"},{"location":"user-guide/overview/","title":"User Guide Overview","text":"<p>Finetune CLI provides a unified, interactive workflow for fine-tuning LLMs.</p>"},{"location":"user-guide/overview/#the-12-step-workflow","title":"The 12-Step Workflow","text":"<p>The CLI guides you through a structured process to ensure successful fine-tuning:</p> <ol> <li>Model Selection: Choose your base model.</li> <li>Dataset Selection: Load your training data.</li> <li>Technique Selection: Choose the best fine-tuning method (LoRA, QLoRA, etc.).</li> <li>Benchmark Selection: Decide how to evaluate success.</li> <li>Output Configuration: Set where to save results.</li> <li>Base Model Benchmarking: Establish a baseline performance.</li> <li>Parameter Configuration: Fine-tune hyperparameters.</li> <li>Training: Execute the fine-tuning process.</li> <li>Fine-tuned Benchmarking: Evaluate the new model.</li> <li>Comparison: Compare Before vs. After results.</li> <li>Saving: Persist model artifacts.</li> <li>Upload: Publish to HuggingFace Hub.</li> </ol>"},{"location":"user-guide/overview/#supported-techniques","title":"Supported Techniques","text":"<ul> <li>Quantization:<ul> <li>LoRA: Standard Low-Rank Adaptation.</li> <li>QLoRA: 4-bit Quantized LoRA for low memory.</li> <li>Prompt Tuning: Soft prompt optimization.</li> <li>Prefix Tuning: (Coming soon)</li> </ul> </li> <li>Distillation: (Coming soon)</li> <li>Pruning: (Coming soon)</li> </ul>"},{"location":"user-guide/overview/#supported-benchmarks","title":"Supported Benchmarks","text":"<ul> <li>ROUGE: For text generation quality.</li> <li>BLEU: (Coming soon)</li> <li>BERTScore: (Coming soon)</li> </ul>"},{"location":"user-guide/training/","title":"Training Process","text":""},{"location":"user-guide/training/#what-happens-during-training","title":"What Happens During Training?","text":"<ol> <li>Model Loading: The base model is loaded (potentially quantized for QLoRA).</li> <li>Adapter Attachment: PEFT adapters (LoRA/Prompt Tuning) are attached to the model.</li> <li>Data Preparation: Dataset is tokenized and batched.</li> <li>Optimization Loop:<ul> <li>Forward pass: Calculate loss.</li> <li>Backward pass: Calculate gradients (only for adapter parameters).</li> <li>Optimizer step: Update weights.</li> </ul> </li> <li>Logging: Loss and other metrics are logged every 10 steps.</li> <li>Checkpointing: Model is saved at the end of each epoch.</li> </ol>"},{"location":"user-guide/training/#monitoring","title":"Monitoring","text":"<p>The CLI displays a progress bar with: *   Current step / Total steps *   Training Loss *   Estimated time remaining</p>"},{"location":"user-guide/training/#hardware-requirements","title":"Hardware Requirements","text":"<ul> <li>LoRA: Requires ~14GB VRAM for a 7B model (fp16).</li> <li>QLoRA: Requires ~6GB VRAM for a 7B model (4-bit).</li> <li>Prompt Tuning: Requires very low VRAM, similar to inference.</li> </ul>"}]}